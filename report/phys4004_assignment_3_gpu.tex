\documentclass{article}

% - Style
\usepackage{base}

% - Plotting
\usepackage{pgfplotstable}
\usepgfplotslibrary{units}
% \usetikzlibrary{external}
% \tikzexternalize[mode=list and make]

% - Listings
\usepackage{color}
\usepackage{listings}

\lstset{
  basicstyle=\ttfamily\footnotesize\color{black}
  , commentstyle=\color{blue}
  , keywordstyle=\color{purple}
  , stringstyle=\color{orange}
  %
  , numbers=left
  , numbersep=5pt
  , stepnumber=1
  , numberstyle=\ttfamily\small\color{black}
  %
  , keepspaces=true
  , showspaces=false
  , showstringspaces=false
  , showtabs=false
  , tabsize=2
  , breaklines=true
  %
  , frame=single
  , backgroundcolor=\color{white}
  , rulecolor=\color{black}
  , captionpos=b
  %
  , language=C
}

% file or folder
\lstdefinestyle{ff}{
  basicstyle=\ttfamily\normalsize\color{orange}
}

\newcommand{\lilf}[1]{\lstinline[style=ff]{#1}}

% - Title
\title{PHYS4004 - Assignment 3 - Game of Life (GPU)}
\author{Tom Ross - 1834 2884}
\date{}

% - Headers
\pagestyle{fancy}
\fancyhf{}
\rhead{\theauthor}
\chead{}
\lhead{\thetitle}
\rfoot{\thepage}
\cfoot{}
\lfoot{}

% - Document
\begin{document}

\tableofcontents

\clearpage
\section{Overview}
\label{sec:overview}

The entire code repository can be found at
\url{https://github.com/dgsaf/game-of-life-gpu}.
Conway's Game of Life has been accelerated using GPU programming with two
models, CUDA and OpenACC, both using C.
The code has been derived from the original code which was provided by Cristian
Di Pietrantonio, and Maciej Cytowski.
It consists of the following items of interest:
\begin{itemize}
\item \lilf{report/}:
  The directory containing this \lilf{tex} and its resulting \lilf{pdf}
  document.

\item \lilf{ex1-gol-cuda/}, \lilf{ex2-gol-gpu-directives/openacc/}:
  The CUDA and OpenACC directories have a similar structure, which consists of:

  \begin{itemize}
  \item \lilf{cpu.slurm}:
    A \lilf{slurm} script for submitting CPU jobs on Topaz, for given
    \lstinline{n, m, nsteps}.
    The CPU code timing output, recorded in [\si{\milli\second}], is written to
    \lstinline{output/timing-cpu.n-<n>.m-<m>.nsteps-<nsteps>.txt}.

  \item \lilf{gpu.slurm}:
    A \lilf{slurm} script for submitting GPU CUDA jobs on Topaz, for given
    \lstinline{n, m, nsteps}.
    The GPU code timing output, recorded in [\si{\milli\second}], is written to
    \lilf{output/timing-gpu-cuda.n-<n>.m-<m>.nsteps-<nsteps>.txt} for the CUDA
    code, and \lilf{output/timing-gpu-openacc.n-<n>.m-<m>.nsteps-<nsteps>.txt}
    for the OpenACC code.

  \item \lilf{jobs.sh}:
    A \lilf{bash} script which batches a set of jobs, for both
    the CPU and the GPU codes, on Topaz, for \lstinline{nsteps = 100} and
    \lstinline{n = m = 1, 2, 4, 8, ..., 16384}.

  \item \lilf{extract.sh}:
    A \lilf{bash} script which, from the jobs batched in \lilf{jobs.sh},
    \lstinline{n = m = 1, 2, 4, 8, ..., 16384}, extracts the timing output
    \lstinline{cpu_elapsed_time, cpu_elapsed_time, kernel_time}, calculates
    \lstinline{speedup}, and writes this performance evaluation to
    \lilf{output/performance.nsteps-<nsteps>.txt}.

  \item \lilf{output/performance.txt}:
    A \lilf{txt} file which, after the jobs have been submitted and the timing
    output extracted, contains for each job
    \lstinline{n = m = 1, 2, 4, 8, ..., 16384} the performance characteristics
    \lstinline{cpu_elapsed_time, cpu_elapsed_time, speedup, kernel_time}.
  \end{itemize}
\end{itemize}

\section{CPU Code}
\label{sec:cpu-code}

The original code for both the CUDA and OpenACC models has been modified
slightly.
\begin{itemize}
\item
  Minor C formatting changes have been made, although only where the original
  code was modified - unmodified regions of the code remain unadjusted.

\item
  Debugging macros have been utilised to annotate the code for clarity, and can
  be compiled away to yield performant code.

\item
  The timing methods in \lilf{common.c}, \lilf{common.h}, have been
  standardised across the CUDA and OpenACC codes; having originally yielding
  different return types in each model.
  The function \lstinline{float get_elapsed_time(struct timeval start)} now
  returns the time since \lstinline{start} was initialised, in
  [\si{\milli\second}], for both codes.

\item
  In \lilf{common.c}, \lilf{common.h}, the ASCII visualisation has been modified
  in the following ways: it truncates the grid so that even large grids can be
  partially visualised in the terminal - allowing for easier verification of
  grid states across codes, it builds the visualisation output in a buffer
  string which is the printed in one call to avoid interference from
  asynchronous terminal behaviour.

\end{itemize}

It should be noted that the debugging macros are also ported to the GPU codes,
and so, are common to the CPU and GPU codes across both models.
The debugging macros are shown in \autoref{lst:debug_macros}, and can be called
with a format string, and variable number of arguments similar to how
\lstinline{printf()} is called.

\lstinputlisting[
label={lst:debug_macros}
, caption={
  Debugging macros from \lilf{ex1-gol-cuda/src/game_of_life.c}.
  Note that these macros are common to both CPU and GPU codes across both
  models.
}
, language=C
, linerange={3-31}
, firstnumber=3
]{../ex1-gol-cuda/src/game_of_life.c}

\clearpage
\section{GPU Code}
\label{sec:Gpu-code}

For both models, on Topaz, the script \lilf{jobs.sh} was used to submit, for
each of \lstinline{n = m = 1, 2, 4, 8, ..., 16384}, pairs of jobs, running the
CPU and GPU codes for these values of \lstinline{n, m}, and with
\lstinline{nsteps = 100}.
The CPU and GPU codes were compiled with \lstinline{-O2}, and with all debugging
macros (including timing and visualisation macros) turned off.
After every job had been completed, the script \lilf{extract.sh} was used to
extract the timing data for the entire job set, and calculate the GPU speedup
relative to the CPU, to the file \lilf{output/performance.nsteps-100.txt}.

\subsection{CUDA Code}
\label{sec:cuda-code}

The performance characteristics of the CUDA code (that is, the extracted timing
data) are shown in \autoref{tab:cuda-performance} and the timing data is plotted
in \autoref{fig:cuda-performance}.

\begin{table}[h]
  \begin{center}
    \pgfplotstabletypeset
    [ multicolumn names
    , col sep=comma
    , display columns/0/.style={
      column name=\lstinline{n = m}
      , fixed
      , dec sep align
    }
    , display columns/1/.style={
      column name=\lstinline{cpu_elapsed_time}
      , fixed
      , fixed zerofill
      , dec sep align
      , precision=2
    }
    , display columns/2/.style={
      column name=\lstinline{gpu_elapsed_time}
      , fixed
      , fixed zerofill
      , dec sep align
      , precision=2
    }
    , display columns/3/.style={
      column name=\lstinline{speedup}
      , fixed
      , fixed zerofill
      , dec sep align
      , precision=4
    }
    , display columns/4/.style={
      column name=\lstinline{kernel_time}
      , fixed
      , fixed zerofill
      , dec sep align
      , precision=2
    }
    , every head row/.style={
      before row={\toprule}
      , after row={\midrule}
    }
    , every last row/.style={
      after row=\bottomrule
    }
    ]{../ex1-gol-cuda/output/performance.nsteps-100.txt}
  \end{center}
  \caption{
    Performance characteristics of CUDA code, compiled with
    \lstinline[language=bash]{-02}, and with debugging statements turned off.
    All times are presented in units of \si{\ms}.
  }
  \label{tab:cuda-performance}
\end{table}

\begin{figure}[h]
  \centering
  \begin{tikzpicture}
    \begin{axis}[
      use units
      , scale = 1.0
      , title = {
        CPU and GPU-CUDA GOL Scaling Performance
      }
      , grid = major
      , xmode = log
      , ymode = log
      , log basis x = {2}
      , log basis y = {10}
      , xmin = 1
      , xmax = 16384
      , xlabel = {\lstinline{n = m}}
      , ylabel = {Time}
      , y unit = {\si{\ms}}
      % , xtick={
      %   1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384
      % }
      , xtick={
        1, 4, 16, 64, 256, 1024, 4096, 16384
      }
      % , xticklabels={
      %   1, 4, 16, 64, 256, 1024, 4096, 16384
      % }
      , legend entries
      , legend style = {
        cells = {anchor=west}
        , legend pos = north west
        , font = \tiny
      }
      ]

      \pgfplotstableread[
      col sep = comma
      , header = true
      ]{../ex1-gol-cuda/output/performance.nsteps-100.txt}{\data}

      \addplot [
      color = black
      , mark = diamond*
      ] table [x index = {0}, y index = {1}] \data;
      \addlegendentry{\lstinline{cpu_elapsed_time}}

      \addplot [
      color = red
      , mark = diamond*
      ] table [x index = {0}, y index = {2}] \data;
      \addlegendentry{\lstinline{gpu_elapsed_time}}

      \addplot [
      color = orange
      , mark = diamond*
      ] table [x index = {0}, y index = {4}] \data;
      \addlegendentry{\lstinline{kernel_time}}
    \end{axis}
  \end{tikzpicture}
  \caption{
    The scaling performance of the CPU and GPU-CUDA GOL codes are shown for
    \lstinline{n = m = 1, 2, 4, 8, ..., 16384}, with \lstinline{nsteps = 100}.
    Note that the x-axis is presented in $\log_{2}$ scale, and the y-axis is
    presented in $\log_{10}$ scale.
  }
  \label{fig:cuda-performance}
\end{figure}

It can be seen that the CPU code is more performant that the GPU-OpenACC code
for small grid sizes up to \lstinline{n = m = 512}.
We note also that is scales exponentially with the grid size, for all grid
sizes.
It can be seen that OpenACC code is uniformly performant for grid sizes up
to \lstinline{n = m = 4096}, at which point it begins to scale exponentially
with the grid size, but at a slower rate than the CPU code.
It can also be seen that \lstinline{kernel_time} is significantly smaller than
\lstinline{gpu_elapsed_time}, and is uniform for grid sizes up to
\lstinline{n = m = 512}, at which point it begins to scale exponentially with
the grid size, until it converges with \lstinline{gpu_elapsed_time}.

This behaviour reflects the nature of GPU programming, in that
\lstinline{gpu_elapsed_time} can be separated into the time spent setting up the
computation on the GPU, \lstinline{setup_time}, and the time it actually takes
the GPU to perform the computation, \lstinline{kernel_time}; that is,
\lstinline{gpu_elapsed_time = setup_time + kernel_time}.
Typically, \lstinline{setup_time} scales constantly with grid size, since it's
limiting factor is usually the I/O between the CPU and the GPU, memory
allocation, et cetera.

For small grid sizes, \lstinline{kernel_time} is significantly smaller than
\lstinline{setup_time}, and so \lstinline{gpu_elapsed_time} scales constantly
with grid size.
For larger grid sizes, \lstinline{kernel_time} increases as the GPU
computational overhead increases, and as the GPU blocks begin to be allocated
larger sections of the grid to work on.
Hence, \lstinline{gpu_elapsed_time} will tend to be pre-dominated by
\lstinline{kernel_time} past a certain grid size, and begin scaling
exponentially.

\clearpage
\subsection{OpenACC Code}
\label{sec:cpu-code}

The performance characteristics of the OpenACC code (that is, the extracted
timing data) are shown in \autoref{tab:openacc-performance} and the timing data is
plotted in \autoref{fig:openacc-performance}.

\begin{table}[h]
  \begin{center}
    \pgfplotstabletypeset
    [ multicolumn names
    , col sep=comma
    , display columns/0/.style={
      column name=\lstinline{n = m}
      , fixed
      , dec sep align
    }
    , display columns/1/.style={
      column name=\lstinline{cpu_elapsed_time}
      , fixed
      , fixed zerofill
      , dec sep align
      , precision=2
    }
    , display columns/2/.style={
      column name=\lstinline{gpu_elapsed_time}
      , fixed
      , fixed zerofill
      , dec sep align
      , precision=2
    }
    , display columns/3/.style={
      column name=\lstinline{speedup}
      , fixed
      , fixed zerofill
      , dec sep align
      , precision=4
    }
    , display columns/4/.style={
      column name=\lstinline{kernel_time}
      , fixed
      , fixed zerofill
      , dec sep align
      , precision=2
    }
    , every head row/.style={
      before row={\toprule}
      , after row={\midrule}
    }
    , every last row/.style={
      after row=\bottomrule
    }
    ]{../ex2-gol-gpu-directives/openacc/output/performance.nsteps-100.txt}
  \end{center}
  \caption{
    Performance characteristics of OpenACC code, compiled with
    \lstinline[language=bash]{-02}, and with debugging statements turned off.
    All times are presented in units of \si{\ms}.
  }
  \label{tab:openacc-performance}
\end{table}

\begin{figure}[h]
  \centering
  \begin{tikzpicture}
    \begin{axis}[
      use units
      , scale = 1.0
      , title = {
        CPU and GPU-OpenACC GOL Scaling Performance
      }
      , grid = major
      , xmode = log
      , ymode = log
      , log basis x = {2}
      , log basis y = {10}
      , xmin = 1
      , xmax = 16384
      , xlabel = {\lstinline{n = m}}
      , ylabel = {Time}
      , y unit = {\si{\ms}}
      % , xtick={
      %   1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384
      % }
      , xtick={
        1, 4, 16, 64, 256, 1024, 4096, 16384
      }
      % , xticklabels={
      %   1, 4, 16, 64, 256, 1024, 4096, 16384
      % }
      , legend entries
      , legend style = {
        cells = {anchor=west}
        , legend pos = north west
        , font = \tiny
      }
      ]

      \pgfplotstableread[
      col sep = comma
      , header = true
      ]{../ex2-gol-gpu-directives/openacc/output/performance.nsteps-100.txt}
      {\data}

      \addplot [
      color = black
      , mark = diamond*
      ] table [x index = {0}, y index = {1}] \data;
      \addlegendentry{\lstinline{cpu_elapsed_time}}

      \addplot [
      color = red
      , mark = diamond*
      ] table [x index = {0}, y index = {2}] \data;
      \addlegendentry{\lstinline{gpu_elapsed_time}}

      \addplot [
      color = orange
      , mark = diamond*
      ] table [x index = {0}, y index = {4}] \data;
      \addlegendentry{\lstinline{kernel_time}}
    \end{axis}
  \end{tikzpicture}
  \caption{
    The scaling performance of the CPU and GPU-OpenACC GOL codes are shown for
    \lstinline{n = m = 1, 2, 4, 8, ..., 16384}, with \lstinline{nsteps = 100}.
    Note that the x-axis is presented in $\log_{2}$ scale, and the y-axis is
    presented in $\log_{10}$ scale.
  }
  \label{fig:openacc-performance}
\end{figure}

It can be seen that the CPU code is more performant that the GPU-OpenACC code
for small grid sizes up to \lstinline{n = m = 512}.
We note also that is scales exponentially with the grid size, for all grid
sizes.
It can be seen that OpenACC code is uniformly performant for grid sizes up
to \lstinline{n = m = 4096}, at which point it begins to scale exponentially
with the grid size, but at a slower rate than the CPU code.
It can also be seen that \lstinline{kernel_time} is significantly smaller than
\lstinline{gpu_elapsed_time}, and is uniform for grid sizes up to
\lstinline{n = m = 512}, at which point it begins to scale exponentially with
the grid size, until it converges with \lstinline{gpu_elapsed_time}.

This behaviour reflects the nature of GPU programming, and was discussed in
detail in \autoref{sec:cuda-code} with regard to the CUDA code, but is similar
for the OpenACC code also.

\end{document}